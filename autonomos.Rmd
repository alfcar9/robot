---
title: "autonomos"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(cache=TRUE)
```

```{r, message=FALSE}
library(imager)
library(jpeg)
library(readr)
library(tidyverse)
library(keras)
library(RcppRoll)
```

```{r create_csv}
#setwd("~/Desktop/1er_Semestre/Aprendzaje Maquina/Proyectos/robot/autonomos-imgs/") #Asegurate de estar parado aqui, corre esto en consola.
#setwd(~/home/egranadoo/autonomos-imgs")

path <- "autonomos-imgs/"
listpaths <- dir(path)
m <- length(listpaths)
file.names <- lapply(1:m, function(i){ 
  path <- paste("autonomos-imgs/", listpaths[i],"/", sep="")
  return(paste("autonomos-imgs/", listpaths[i],"/", dir(path), sep=""))
})

file.names[[4]] <- sample(file.names[[4]], 0.05*length(file.names[[4]]))
                          
file.names <- flatten_chr(file.names)
```

```{r, cache=TRUE}
resol <- 30   # recomiendo 10, 20, 30, ...etc Es el tamaÃ±o de la imagen reducida en porcentaje. 10% de la imagen original, por ejemplo.
num_obs <- length(file.names)
dim <- (resol/100*480)*(resol/100*640)
image_df <- rep(NA, dim) %>% t() %>% as.data.frame()

for(i in 1:num_obs){
  im <- load.image(file.names[i])
  thmb <- (resize(im,-resol,-resol) %>% imsplit("c"))[[2]]
  image_df[i,] <- (as.data.frame(thmb))$value %>% t()
}
```

```{r}
m <- 480*640*(resol/100)^2
nrow <- 480*resol/100
ncol <- 640*resol/100

image_df[,(m+1)] <- rbinom(nrow(image_df), 1, prob = 0.2)
colnames(image_df)[length(image_df)] <- "estado" 
```

```{r}
mostrar_imagen <- function(renglon, dat){
  v <- as.numeric(dat %>% dplyr::select(contains('V'))%>% .[renglon,])
  mat <- (t(matrix(v, nrow = nrow, ncol = ncol, byrow=T))[,nrow:1])
  image(mat, axes = F, col=gray(0:255/255))
}
```

```{r, fig.height=4}
mostrar_imagen(2, image_df)
```

```{r}
set.seed(130912)

trainid <- sample(1:num_obs, floor(num_obs*.7))
testid <- setdiff(1:num_obs, trainid)

train <- image_df[trainid, ]
test <-  image_df[testid, ]

x_train <- train %>% dplyr::select(-estado) %>% as.matrix
dim(x_train) <- c(nrow(x_train), nrow, ncol, 1)
estado_train <- train %>% dplyr::select(estado) %>% flatten_dbl()
y_train <- to_categorical(estado_train, 2)

x_test <- test %>% dplyr::select(-estado) %>% as.matrix()
dim(x_test) <- c(nrow(x_test), nrow, ncol, 1)
estado_test <- test %>% dplyr::select(estado) %>% flatten_dbl()
y_test <- to_categorical(estado_test, 2)
```


```{r}
lambda1 <- 0.01
lambda2 <- 0.01
filtro1 <- 4
filtro2 <- 12
neuronas <- 20
lr1 <- 0.045
momentum1 <- 0.9

model <- keras_model_sequential() 
model %>%
layer_conv_2d(filters = filtro1, kernel_size = c(3,3), activation = 'relu',
              input_shape = c(nrow, ncol, 1), padding ='same',
              kernel_regularizer = regularizer_l2(lambda1) ) %>%
              layer_max_pooling_2d(pool_size = c(2, 2)) %>% 
              layer_dropout(rate = 0.25) %>%
  
layer_conv_2d(filters = filtro2, kernel_size = c(3,3), activation = 'relu',
              input_shape = c(nrow, ncol, 1), padding ='same',
              kernel_regularizer = regularizer_l2(lambda2) ) %>%
              layer_max_pooling_2d(pool_size = c(2, 2)) %>% 
              layer_dropout(rate = 0.25) %>% 
  
layer_flatten() %>% 
layer_dense(units = neuronas, activation = 'relu') %>%
layer_dropout(rate = 0.50) %>%
layer_dense(units = 2, activation = 'softmax')

model %>% compile(
  loss = 'categorical_crossentropy',
  optimizer = optimizer_sgd(lr = lr1, momentum = momentum1),
  metrics = c('accuracy','categorical_crossentropy')
)
history <- model %>% fit(
  x_train, y_train,
  epochs = 20, batch_size = (ncol*nrow), 
  validation_data = list(x_test, y_test))

model_serialized <- serialize_model(model)

#score <- (model$evaluate(x_test, y_test) %>% flatten_dbl())[1]
```
